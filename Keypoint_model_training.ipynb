{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "igMyGnjE9hEp"
      },
      "outputs": [],
      "source": [
        "import csv\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "RANDOM_SEED = 42"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t2HDvhIu9hEr"
      },
      "source": [
        "# Specify each path"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "9NvZP2Zn9hEy"
      },
      "outputs": [],
      "source": [
        "# Specify data paths\n",
        "dataset = 'model/keypoint_classifier/keypoint.csv'\n",
        "model_save_path = 'model/keypoint_classifier/keypoint_classifier.hdf5'\n",
        "tflite_save_path = 'model/keypoint_classifier/keypoint_classifier.tflite'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s5oMH7x19hEz"
      },
      "source": [
        "# Set number of classes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "id": "du4kodXL9hEz"
      },
      "outputs": [],
      "source": [
        "# Change training classes if necessary\n",
        "NUM_CLASSES = 3"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XjnL0uso9hEz"
      },
      "source": [
        "# Dataset reading"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "id": "QT5ZqtEz9hE0"
      },
      "outputs": [],
      "source": [
        "X_dataset = np.loadtxt(dataset, delimiter=',', dtype='float32', usecols=list(range(1, (21 * 2) + 1)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "id": "QmoKFsp49hE0"
      },
      "outputs": [],
      "source": [
        "y_dataset = np.loadtxt(dataset, delimiter=',', dtype='int32', usecols=(0))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "id": "xQU7JTZ_9hE0"
      },
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X_dataset, y_dataset, train_size=0.75, random_state=RANDOM_SEED)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "id": "xElG5FoPDQO9",
        "outputId": "2ef372ed-62e3-49c1-ad36-a5b5dc76701a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(array([1, 2, 3]), array([17, 25, 34], dtype=int64))\n"
          ]
        },
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAh8AAAGYCAYAAADiAIAsAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjYuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8o6BhiAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAcbklEQVR4nO3df4xV9Z3/8deAMEplhgDCzMShpf6mCt2lFWe1FCsV8RtWV7pr202KttHYgomQpn5nY1Xc3UzTbip1F2GzqdJmy9p1U+3ab4upbME2BRW6lHabsoXVSKMzVDfM4FhGAvP9o3F2p6LtwJ3P5Q6PR3IS7jnn3vu+8Zp55txzz63r7+/vDwBAIaOqPQAAcHIRHwBAUeIDAChKfAAARYkPAKAo8QEAFCU+AICixAcAUNQp1R7gtx05ciQvvPBCxo8fn7q6umqPAwD8Hvr7+3PgwIG0tLRk1Ki3PrZxwsXHCy+8kNbW1mqPAQAcg7179+bMM898y31OuPgYP358kt8M39DQUOVpAIDfR09PT1pbWwf+jr+VEy4+Xv+opaGhQXwAQI35fU6ZcMIpAFCU+AAAihIfAEBRJ9w5H7+vw4cP59ChQ9UeY1iMGTMmo0ePrvYYADAsai4++vv709nZmf3791d7lGE1YcKENDU1udYJACNOzcXH6+ExZcqUjBs3bsT9ce7v78+rr76affv2JUmam5urPBEAVFZNxcfhw4cHwmPSpEnVHmfYnHbaaUmSffv2ZcqUKT6CAWBEqakTTl8/x2PcuHFVnmT4vf4aR+p5LQCcvGoqPl430j5qOZqT4TUCcHKqyfgAAGqX+AAAiqqpE07fyjv+7/8r+nzPfe7/HNP9Vq9enS984Qvp7OzMrFmz8rd/+7e5+OKLKzwdAJy4HPko6Otf/3pWrFiRu+66Kz/60Y8ya9asLFiwYOBrtQBwMhAfBX3xi1/MTTfdlBtvvDEzZszI2rVrM27cuDzwwAPVHg0AihkxH7uc6F577bVs37497e3tA+tGjRqV+fPnZ8uWLVWcDGAY3d1Y7QlGjru7qz1BxTjyUchLL72Uw4cPZ+rUqYPWT506NZ2dnVWaCgDKEx8AQFHio5DJkydn9OjR6erqGrS+q6srTU1NVZoKAMoTH4WMHTs2s2fPzsaNGwfWHTlyJBs3bkxbW1sVJwOAspxwWtCKFSuyZMmSvOc978nFF1+cVatWpbe3NzfeeGO1RwOAYkZMfBzrRb9Kuv766/OrX/0qd955Zzo7O/Pud787GzZseMNJqAAwko2Y+KgVy5Yty7Jly6o9BgBUjXM+AICixAcAUJT4AACKEh8AQFHiAwAoSnwAAEWJDwCgqCHFx5o1azJz5sw0NDSkoaEhbW1t+c53vjOwfd68eamrqxu03HLLLRUfGgCoXUO6yNiZZ56Zz33ucznnnHPS39+fr3zlK7nmmmvy7//+73nXu96VJLnppptyzz33DNxn3LhxlZ0YAKhpQzrysWjRolx99dU555xzcu655+av//qvc/rpp2fr1q0D+4wbNy5NTU0DS0NDQ8WHrkVPPvlkFi1alJaWltTV1eXRRx+t9kgAUBXHfHn1w4cP5+GHH05vb++gX2X92te+ln/8x39MU1NTFi1alM9+9rNvefSjr68vfX19A7d7enqObaC7G4/tfsfq7u4h7d7b25tZs2bl4x//eK677rphGgoATnxDjo+f/OQnaWtry8GDB3P66afnkUceyYwZM5IkH/3oR/P2t789LS0t2blzZ26//fbs2rUr3/jGN9708To6OrJy5cpjfwU1YuHChVm4cGG1xwCAqhtyfJx33nnZsWNHuru78y//8i9ZsmRJNm/enBkzZuTmm28e2O+iiy5Kc3NzrrjiiuzZsydnnXXWUR+vvb09K1asGLjd09OT1tbWY3gpAEAtGHJ8jB07NmeffXaSZPbs2XnmmWfypS99KX//93//hn3nzJmTJNm9e/ebxkd9fX3q6+uHOgYAUKOO+zofR44cGXTOxv+2Y8eOJElzc/PxPg0AMEIM6chHe3t7Fi5cmGnTpuXAgQNZv359Nm3alMcffzx79uzJ+vXrc/XVV2fSpEnZuXNnli9fnrlz52bmzJnDNT8AUGOGFB/79u3Lxz72sbz44otpbGzMzJkz8/jjj+eDH/xg9u7dmyeeeCKrVq1Kb29vWltbs3jx4txxxx3DNTsAUIOGFB9f/vKX33Rba2trNm/efNwDjVSvvPJKdu/ePXD72WefzY4dOzJx4sRMmzatipMBQFnHfJ0Phmbbtm25/PLLB26//g2fJUuWZN26dVWaCgDKGznxMcSLfpU2b9689Pf3V3sMAKg6v2oLABQlPgCAosQHAFCU+AAAihIfAEBRNRkfJ8O3Rk6G1wjAyamm4mPMmDFJkldffbXKkwy/11/j668ZAEaKmrrOx+jRozNhwoTs27cvSTJu3LjU1dVVearK6u/vz6uvvpp9+/ZlwoQJGT16dLVHAoCKqqn4SJKmpqYkGQiQkWrChAkDrxUARpKai4+6uro0NzdnypQpOXToULXHGRZjxoxxxAOAEavm4uN1o0eP9gcaAGpQTZ1wCgDUPvEBABQlPgCAosQHAFCU+AAAihIfAEBR4gMAKEp8AABFiQ8AoCjxAQAUJT4AgKLEBwBQlPgAAIoSHwBAUeIDAChKfAAARYkPAKAo8QEAFCU+AICixAcAUJT4AACKEh8AQFHiAwAoSnwAAEUNKT7WrFmTmTNnpqGhIQ0NDWlra8t3vvOdge0HDx7M0qVLM2nSpJx++ulZvHhxurq6Kj40AFC7hhQfZ555Zj73uc9l+/bt2bZtWz7wgQ/kmmuuyX/8x38kSZYvX57HHnssDz/8cDZv3pwXXngh11133bAMDgDUprr+/v7+43mAiRMn5gtf+EI+9KEP5Ywzzsj69evzoQ99KEny85//PBdccEG2bNmSSy655Pd6vJ6enjQ2Nqa7uzsNDQ3HMxoA1XZ3Y7UnGDnu7q72BG9pKH+/j/mcj8OHD+ehhx5Kb29v2trasn379hw6dCjz588f2Of888/PtGnTsmXLljd9nL6+vvT09AxaAICRa8jx8ZOf/CSnn3566uvrc8stt+SRRx7JjBkz0tnZmbFjx2bChAmD9p86dWo6Ozvf9PE6OjrS2Ng4sLS2tg75RQAAtWPI8XHeeedlx44deeqpp/LJT34yS5Ysyc9+9rNjHqC9vT3d3d0Dy969e4/5sQCAE98pQ73D2LFjc/bZZydJZs+enWeeeSZf+tKXcv311+e1117L/v37Bx396OrqSlNT05s+Xn19ferr64c+OQBQk477Oh9HjhxJX19fZs+enTFjxmTjxo0D23bt2pXnn38+bW1tx/s0AMAIMaQjH+3t7Vm4cGGmTZuWAwcOZP369dm0aVMef/zxNDY25hOf+ERWrFiRiRMnpqGhIbfeemva2tp+72+6AAAj35DiY9++ffnYxz6WF198MY2NjZk5c2Yef/zxfPCDH0yS3HvvvRk1alQWL16cvr6+LFiwIPfff/+wDA4A1Kbjvs5HpbnOB8AI4jofleM6HwAAx0Z8AABFiQ8AoCjxAQAUJT4AgKLEBwBQlPgAAIoSHwBAUeIDAChKfAAARYkPAKAo8QEAFCU+AICixAcAUJT4AACKEh8AQFHiAwAoSnwAAEWJDwCgKPEBABQlPgCAosQHAFDUKdUeAKiguxurPcHIcXd3tSeAEcuRDwCgKPEBABQlPgCAosQHAFCU+AAAihIfAEBR4gMAKEp8AABFiQ8AoCjxAQAUJT4AgKLEBwBQlPgAAIoaUnx0dHTkve99b8aPH58pU6bk2muvza5duwbtM2/evNTV1Q1abrnllooODQDUriHFx+bNm7N06dJs3bo13/3ud3Po0KFceeWV6e3tHbTfTTfdlBdffHFg+fznP1/RoQGA2nXKUHbesGHDoNvr1q3LlClTsn379sydO3dg/bhx49LU1FSZCQGAEeW4zvno7u5OkkycOHHQ+q997WuZPHlyLrzwwrS3t+fVV189nqcBAEaQIR35+N+OHDmS2267LZdeemkuvPDCgfUf/ehH8/a3vz0tLS3ZuXNnbr/99uzatSvf+MY3jvo4fX196evrG7jd09NzrCMBADXgmONj6dKl+elPf5of/OAHg9bffPPNA/++6KKL0tzcnCuuuCJ79uzJWWed9YbH6ejoyMqVK491DACgxhzTxy7Lli3Lt771rXzve9/LmWee+Zb7zpkzJ0mye/fuo25vb29Pd3f3wLJ3795jGQkAqBFDOvLR39+fW2+9NY888kg2bdqU6dOn/8777NixI0nS3Nx81O319fWpr68fyhgAQA0bUnwsXbo069evzze/+c2MHz8+nZ2dSZLGxsacdtpp2bNnT9avX5+rr746kyZNys6dO7N8+fLMnTs3M2fOHJYXAADUliHFx5o1a5L85kJi/9uDDz6YG264IWPHjs0TTzyRVatWpbe3N62trVm8eHHuuOOOig0MANS2IX/s8lZaW1uzefPm4xoIABjZ/LYLAFCU+AAAihIfAEBR4gMAKEp8AABFiQ8AoCjxAQAUJT4AgKLEBwBQlPgAAIoSHwBAUeIDAChKfAAARYkPAKAo8QEAFCU+AICixAcAUJT4AACKEh8AQFHiAwAoSnwAAEWJDwCgKPEBABQlPgCAosQHAFCU+AAAihIfAEBR4gMAKEp8AABFiQ8AoCjxAQAUJT4AgKLEBwBQlPgAAIoSHwBAUeIDAChKfAAARQ0pPjo6OvLe974348ePz5QpU3Lttddm165dg/Y5ePBgli5dmkmTJuX000/P4sWL09XVVdGhAYDaNaT42Lx5c5YuXZqtW7fmu9/9bg4dOpQrr7wyvb29A/ssX748jz32WB5++OFs3rw5L7zwQq677rqKDw4A1KZThrLzhg0bBt1et25dpkyZku3bt2fu3Lnp7u7Ol7/85axfvz4f+MAHkiQPPvhgLrjggmzdujWXXHJJ5SYHAGrScZ3z0d3dnSSZOHFikmT79u05dOhQ5s+fP7DP+eefn2nTpmXLli1HfYy+vr709PQMWgCAkeuY4+PIkSO57bbbcumll+bCCy9MknR2dmbs2LGZMGHCoH2nTp2azs7Ooz5OR0dHGhsbB5bW1tZjHQkAqAHHHB9Lly7NT3/60zz00EPHNUB7e3u6u7sHlr179x7X4wEAJ7YhnfPxumXLluVb3/pWnnzyyZx55pkD65uamvLaa69l//79g45+dHV1pamp6aiPVV9fn/r6+mMZAwCoQUM68tHf359ly5blkUceyb/9279l+vTpg7bPnj07Y8aMycaNGwfW7dq1K88//3za2toqMzEAUNOGdORj6dKlWb9+fb75zW9m/PjxA+dxNDY25rTTTktjY2M+8YlPZMWKFZk4cWIaGhpy6623pq2tzTddAIAkQ4yPNWvWJEnmzZs3aP2DDz6YG264IUly7733ZtSoUVm8eHH6+vqyYMGC3H///RUZFgCofUOKj/7+/t+5z6mnnprVq1dn9erVxzwUADBy+W0XAKAo8QEAFCU+AICixAcAUJT4AACKEh8AQFHiAwAoSnwAAEWJDwCgKPEBABQlPgCAosQHAFDUkH5Yjt9yd2O1JxgZ7u6u9gQAFOTIBwBQlPgAAIoSHwBAUeIDAChKfAAARYkPAKAo8QEAFCU+AICixAcAUJT4AACKEh8AQFHiAwAoSnwAAEWJDwCgKPEBABQlPgCAosQHAFCU+AAAihIfAEBR4gMAKEp8AABFiQ8AoCjxAQAUNeT4ePLJJ7No0aK0tLSkrq4ujz766KDtN9xwQ+rq6gYtV111VaXmBQBq3JDjo7e3N7Nmzcrq1avfdJ+rrroqL7744sDyT//0T8c1JAAwcpwy1DssXLgwCxcufMt96uvr09TUdMxDAQAj17Cc87Fp06ZMmTIl5513Xj75yU/m5ZdfHo6nAQBq0JCPfPwuV111Va677rpMnz49e/bsyV/8xV9k4cKF2bJlS0aPHv2G/fv6+tLX1zdwu6enp9IjAQAnkIrHx4c//OGBf1900UWZOXNmzjrrrGzatClXXHHFG/bv6OjIypUrKz0GAHCCGvav2r7zne/M5MmTs3v37qNub29vT3d398Cyd+/e4R4JAKiiih/5+G2//OUv8/LLL6e5ufmo2+vr61NfXz/cYwAAJ4ghx8crr7wy6CjGs88+mx07dmTixImZOHFiVq5cmcWLF6epqSl79uzJZz7zmZx99tlZsGBBRQcHAGrTkONj27Ztufzyywdur1ixIkmyZMmSrFmzJjt37sxXvvKV7N+/Py0tLbnyyivzl3/5l45uAABJjiE+5s2bl/7+/jfd/vjjjx/XQADAyOa3XQCAosQHAFCU+AAAihIfAEBR4gMAKEp8AABFiQ8AoCjxAQAUJT4AgKLEBwBQlPgAAIoSHwBAUeIDAChKfAAARYkPAKAo8QEAFCU+AICixAcAUJT4AACKEh8AQFHiAwAoSnwAAEWJDwCgKPEBABQlPgCAosQHAFCU+AAAihIfAEBR4gMAKEp8AABFiQ8AoCjxAQAUJT4AgKLEBwBQlPgAAIoSHwBAUeIDAChqyPHx5JNPZtGiRWlpaUldXV0effTRQdv7+/tz5513prm5Oaeddlrmz5+fX/ziF5WaFwCocUOOj97e3syaNSurV68+6vbPf/7zue+++7J27do89dRTedvb3pYFCxbk4MGDxz0sAFD7ThnqHRYuXJiFCxcedVt/f39WrVqVO+64I9dcc02S5Ktf/WqmTp2aRx99NB/+8IePb1oAoOZV9JyPZ599Np2dnZk/f/7AusbGxsyZMydbtmw56n36+vrS09MzaAEARq6KxkdnZ2eSZOrUqYPWT506dWDbb+vo6EhjY+PA0traWsmRAIATTNW/7dLe3p7u7u6BZe/evdUeCQAYRhWNj6ampiRJV1fXoPVdXV0D235bfX19GhoaBi0AwMhV0fiYPn16mpqasnHjxoF1PT09eeqpp9LW1lbJpwIAatSQv+3yyiuvZPfu3QO3n3322ezYsSMTJ07MtGnTctttt+Wv/uqvcs4552T69On57Gc/m5aWllx77bWVnBsAqFFDjo9t27bl8ssvH7i9YsWKJMmSJUuybt26fOYzn0lvb29uvvnm7N+/P5dddlk2bNiQU089tXJTAwA1a8jxMW/evPT397/p9rq6utxzzz255557jmswAGBkqvq3XQCAk4v4AACKEh8AQFHiAwAoSnwAAEWJDwCgKPEBABQlPgCAosQHAFCU+AAAihIfAEBR4gMAKEp8AABFiQ8AoCjxAQAUJT4AgKLEBwBQlPgAAIoSHwBAUeIDAChKfAAARYkPAKAo8QEAFCU+AICixAcAUJT4AACKEh8AQFHiAwAoSnwAAEWJDwCgKPEBABQlPgCAosQHAFCU+AAAihIfAEBR4gMAKEp8AABFVTw+7r777tTV1Q1azj///Eo/DQBQo04Zjgd917velSeeeOJ/nuSUYXkaAKAGDUsVnHLKKWlqahqOhwYAatywnPPxi1/8Ii0tLXnnO9+ZP//zP8/zzz//pvv29fWlp6dn0AIAjFwVj485c+Zk3bp12bBhQ9asWZNnn30273vf+3LgwIGj7t/R0ZHGxsaBpbW1tdIjAQAnkIrHx8KFC/Onf/qnmTlzZhYsWJBvf/vb2b9/f/75n//5qPu3t7enu7t7YNm7d2+lRwIATiDDfibohAkTcu6552b37t1H3V5fX5/6+vrhHgMAOEEM+3U+XnnllezZsyfNzc3D/VQAQA2oeHx8+tOfzubNm/Pcc8/lhz/8Yf7kT/4ko0ePzkc+8pFKPxUAUIMq/rHLL3/5y3zkIx/Jyy+/nDPOOCOXXXZZtm7dmjPOOKPSTwUA1KCKx8dDDz1U6YcEAEYQv+0CABQlPgCAosQHAFCU+AAAihIfAEBR4gMAKEp8AABFiQ8AoCjxAQAUJT4AgKLEBwBQlPgAAIqq+A/LAcDr3nFwfbVHGDGeq/YAFeTIBwBQlPgAAIoSHwBAUeIDAChKfAAARYkPAKAo8QEAFCU+AICiXGQMRhAXdKqc56o9AIxgjnwAAEWJDwCgKPEBABQlPgCAosQHAFCU+AAAihIfAEBR4gMAKEp8AABFucLpcXA1ycp4rtoDAFCUIx8AQFHiAwAoSnwAAEWJDwCgqGGLj9WrV+cd73hHTj311MyZMydPP/30cD0VAFBDhiU+vv71r2fFihW566678qMf/SizZs3KggULsm/fvuF4OgCghgxLfHzxi1/MTTfdlBtvvDEzZszI2rVrM27cuDzwwAPD8XQAQA2p+HU+XnvttWzfvj3t7e0D60aNGpX58+dny5Ytb9i/r68vfX19A7e7u7uTJD09PZUereKO9L1a7RFGhFr4b10rvCcrx/uyMrwnK+dEf0++Pl9/f//v3Lfi8fHSSy/l8OHDmTp16qD1U6dOzc9//vM37N/R0ZGVK1e+YX1ra2ulR+ME1biq2hPAG3lfcqKplffkgQMH0tjY+Jb7VP0Kp+3t7VmxYsXA7SNHjuS///u/M2nSpNTV1VVxstrX09OT1tbW7N27Nw0NDdUeB7wnOSF5X1ZGf39/Dhw4kJaWlt+5b8XjY/LkyRk9enS6uroGre/q6kpTU9Mb9q+vr099ff2gdRMmTKj0WCe1hoYG/0NxQvGe5ETkfXn8ftcRj9dV/ITTsWPHZvbs2dm4cePAuiNHjmTjxo1pa2ur9NMBADVmWD52WbFiRZYsWZL3vOc9ufjii7Nq1ar09vbmxhtvHI6nAwBqyLDEx/XXX59f/epXufPOO9PZ2Zl3v/vd2bBhwxtOQmV41dfX56677nrDx1pQLd6TnIi8L8ur6/99vhMDAFAhftsFAChKfAAARYkPAKAo8QEAFCU+AICiqn55dSrnpZdeygMPPJAtW7aks7MzSdLU1JQ/+qM/yg033JAzzjijyhMCgCMfI8YzzzyTc889N/fdd18aGxszd+7czJ07N42Njbnvvvty/vnnZ9u2bdUeEwbZu3dvPv7xj1d7DE4yv/71r/ODH/wgP/vZz96w7eDBg/nqV79ahalOLq7zMUJccsklmTVrVtauXfuGH+Tr7+/PLbfckp07d2bLli1VmhDe6Mc//nH+8A//MIcPH672KJwk/vM//zNXXnllnn/++dTV1eWyyy7LQw89lObm5iS/+R2ylpYW78lh5mOXEeLHP/5x1q1bd9RfAq6rq8vy5cvzB3/wB1WYjJPZv/7rv77l9v/6r/8qNAn8xu23354LL7ww27Zty/79+3Pbbbfl0ksvzaZNmzJt2rRqj3fSEB8jRFNTU55++umcf/75R93+9NNPu7w9xV177bWpq6vLWx1gPVoww3D54Q9/mCeeeCKTJ0/O5MmT89hjj+VTn/pU3ve+9+V73/te3va2t1V7xJOC+BghPv3pT+fmm2/O9u3bc8UVVwyERldXVzZu3Jh/+Id/yN/8zd9UeUpONs3Nzbn//vtzzTXXHHX7jh07Mnv27MJTcTL79a9/nVNO+Z8/fXV1dVmzZk2WLVuW97///Vm/fn0Vpzt5iI8RYunSpZk8eXLuvffe3H///QOfV44ePTqzZ8/OunXr8md/9mdVnpKTzezZs7N9+/Y3jY/fdVQEKu31k+8vuOCCQev/7u/+Lknyx3/8x9UY66TjhNMR6NChQ3nppZeSJJMnT86YMWOqPBEnq+9///vp7e3NVVddddTtvb292bZtW97//vcXnoyTVUdHR77//e/n29/+9lG3f+pTn8ratWtz5MiRwpOdXMQHAFCU63wAAEWJDwCgKPEBABQlPgCAosQHAFCU+AAAihIfAEBR4gMAKOr/A9PFwtpvuT9MAAAAAElFTkSuQmCC",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Classes count\n",
        "counts = np.unique(y_dataset, return_counts=True)\n",
        "df = pd.DataFrame(counts)\n",
        "df.T.plot(kind=\"bar\", stacked=True)\n",
        "print(counts)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mxK_lETT9hE0"
      },
      "source": [
        "# Model building"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "id": "vHBmUf1t9hE1"
      },
      "outputs": [],
      "source": [
        "model = tf.keras.models.Sequential([\n",
        "    tf.keras.layers.Input((21 * 2, )),\n",
        "    tf.keras.layers.Dropout(0.0),\n",
        "    tf.keras.layers.Dense(32, activation='relu'),\n",
        "    tf.keras.layers.Dropout(0.0),\n",
        "    tf.keras.layers.Dense(32, activation='relu'),\n",
        "    tf.keras.layers.Dropout(0.0),\n",
        "    tf.keras.layers.Dense(16, activation='relu'),\n",
        "    tf.keras.layers.Dense(NUM_CLASSES, activation='softmax')\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ypqky9tc9hE1",
        "outputId": "c42f3550-ceee-45b8-d40d-d99fd84a2616"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dropout_9 (Dropout)         (None, 42)                0         \n",
            "                                                                 \n",
            " dense_12 (Dense)            (None, 32)                1376      \n",
            "                                                                 \n",
            " dropout_10 (Dropout)        (None, 32)                0         \n",
            "                                                                 \n",
            " dense_13 (Dense)            (None, 32)                1056      \n",
            "                                                                 \n",
            " dropout_11 (Dropout)        (None, 32)                0         \n",
            "                                                                 \n",
            " dense_14 (Dense)            (None, 16)                528       \n",
            "                                                                 \n",
            " dense_15 (Dense)            (None, 3)                 51        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 3,011\n",
            "Trainable params: 3,011\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model.summary()  # tf.keras.utils.plot_model(model, show_shapes=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "id": "MbMjOflQ9hE1"
      },
      "outputs": [],
      "source": [
        "# Model checkpoint callback\n",
        "cp_callback = tf.keras.callbacks.ModelCheckpoint(\n",
        "    model_save_path, verbose=1, save_weights_only=False, save_best_only=True)\n",
        "# Callback for early stopping\n",
        "es_callback = tf.keras.callbacks.EarlyStopping(patience=50, verbose=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "id": "c3Dac0M_9hE2"
      },
      "outputs": [],
      "source": [
        "# Model compilation\n",
        "model.compile(\n",
        "    optimizer='adam',\n",
        "    loss='sparse_categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7XI0j1Iu9hE2"
      },
      "source": [
        "# Model training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "id": "WirBl-JE9hE3",
        "scrolled": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: nan - accuracy: 0.3509\n",
            "Epoch 1: val_loss did not improve from inf\n",
            "1/1 [==============================] - 1s 502ms/step - loss: nan - accuracy: 0.3509 - val_loss: nan - val_accuracy: 0.0000e+00\n",
            "Epoch 2/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: nan - accuracy: 0.0000e+00\n",
            "Epoch 2: val_loss did not improve from inf\n",
            "1/1 [==============================] - 0s 52ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
            "Epoch 3/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: nan - accuracy: 0.0000e+00\n",
            "Epoch 3: val_loss did not improve from inf\n",
            "1/1 [==============================] - 0s 37ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
            "Epoch 4/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: nan - accuracy: 0.0000e+00\n",
            "Epoch 4: val_loss did not improve from inf\n",
            "1/1 [==============================] - 0s 38ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
            "Epoch 5/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: nan - accuracy: 0.0000e+00\n",
            "Epoch 5: val_loss did not improve from inf\n",
            "1/1 [==============================] - 0s 43ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
            "Epoch 6/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: nan - accuracy: 0.0000e+00\n",
            "Epoch 6: val_loss did not improve from inf\n",
            "1/1 [==============================] - 0s 32ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
            "Epoch 7/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: nan - accuracy: 0.0000e+00\n",
            "Epoch 7: val_loss did not improve from inf\n",
            "1/1 [==============================] - 0s 33ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
            "Epoch 8/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: nan - accuracy: 0.0000e+00\n",
            "Epoch 8: val_loss did not improve from inf\n",
            "1/1 [==============================] - 0s 37ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
            "Epoch 9/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: nan - accuracy: 0.0000e+00\n",
            "Epoch 9: val_loss did not improve from inf\n",
            "1/1 [==============================] - 0s 31ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
            "Epoch 10/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: nan - accuracy: 0.0000e+00\n",
            "Epoch 10: val_loss did not improve from inf\n",
            "1/1 [==============================] - 0s 26ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
            "Epoch 11/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: nan - accuracy: 0.0000e+00\n",
            "Epoch 11: val_loss did not improve from inf\n",
            "1/1 [==============================] - 0s 32ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
            "Epoch 12/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: nan - accuracy: 0.0000e+00\n",
            "Epoch 12: val_loss did not improve from inf\n",
            "1/1 [==============================] - 0s 33ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
            "Epoch 13/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: nan - accuracy: 0.0000e+00\n",
            "Epoch 13: val_loss did not improve from inf\n",
            "1/1 [==============================] - 0s 33ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
            "Epoch 14/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: nan - accuracy: 0.0000e+00\n",
            "Epoch 14: val_loss did not improve from inf\n",
            "1/1 [==============================] - 0s 33ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
            "Epoch 15/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: nan - accuracy: 0.0000e+00\n",
            "Epoch 15: val_loss did not improve from inf\n",
            "1/1 [==============================] - 0s 38ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
            "Epoch 16/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: nan - accuracy: 0.0000e+00\n",
            "Epoch 16: val_loss did not improve from inf\n",
            "1/1 [==============================] - 0s 32ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
            "Epoch 17/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: nan - accuracy: 0.0000e+00\n",
            "Epoch 17: val_loss did not improve from inf\n",
            "1/1 [==============================] - 0s 36ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
            "Epoch 18/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: nan - accuracy: 0.0000e+00\n",
            "Epoch 18: val_loss did not improve from inf\n",
            "1/1 [==============================] - 0s 26ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
            "Epoch 19/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: nan - accuracy: 0.0000e+00\n",
            "Epoch 19: val_loss did not improve from inf\n",
            "1/1 [==============================] - 0s 30ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
            "Epoch 20/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: nan - accuracy: 0.0000e+00\n",
            "Epoch 20: val_loss did not improve from inf\n",
            "1/1 [==============================] - 0s 26ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
            "Epoch 21/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: nan - accuracy: 0.0000e+00\n",
            "Epoch 21: val_loss did not improve from inf\n",
            "1/1 [==============================] - 0s 26ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
            "Epoch 22/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: nan - accuracy: 0.0000e+00\n",
            "Epoch 22: val_loss did not improve from inf\n",
            "1/1 [==============================] - 0s 29ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
            "Epoch 23/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: nan - accuracy: 0.0000e+00\n",
            "Epoch 23: val_loss did not improve from inf\n",
            "1/1 [==============================] - 0s 23ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
            "Epoch 24/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: nan - accuracy: 0.0000e+00\n",
            "Epoch 24: val_loss did not improve from inf\n",
            "1/1 [==============================] - 0s 28ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
            "Epoch 25/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: nan - accuracy: 0.0000e+00\n",
            "Epoch 25: val_loss did not improve from inf\n",
            "1/1 [==============================] - 0s 26ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
            "Epoch 26/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: nan - accuracy: 0.0000e+00\n",
            "Epoch 26: val_loss did not improve from inf\n",
            "1/1 [==============================] - 0s 24ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
            "Epoch 27/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: nan - accuracy: 0.0000e+00\n",
            "Epoch 27: val_loss did not improve from inf\n",
            "1/1 [==============================] - 0s 27ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
            "Epoch 28/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: nan - accuracy: 0.0000e+00\n",
            "Epoch 28: val_loss did not improve from inf\n",
            "1/1 [==============================] - 0s 24ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
            "Epoch 29/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: nan - accuracy: 0.0000e+00\n",
            "Epoch 29: val_loss did not improve from inf\n",
            "1/1 [==============================] - 0s 26ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
            "Epoch 30/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: nan - accuracy: 0.0000e+00\n",
            "Epoch 30: val_loss did not improve from inf\n",
            "1/1 [==============================] - 0s 26ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
            "Epoch 31/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: nan - accuracy: 0.0000e+00\n",
            "Epoch 31: val_loss did not improve from inf\n",
            "1/1 [==============================] - 0s 25ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
            "Epoch 32/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: nan - accuracy: 0.0000e+00\n",
            "Epoch 32: val_loss did not improve from inf\n",
            "1/1 [==============================] - 0s 24ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
            "Epoch 33/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: nan - accuracy: 0.0000e+00\n",
            "Epoch 33: val_loss did not improve from inf\n",
            "1/1 [==============================] - 0s 26ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
            "Epoch 34/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: nan - accuracy: 0.0000e+00\n",
            "Epoch 34: val_loss did not improve from inf\n",
            "1/1 [==============================] - 0s 27ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
            "Epoch 35/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: nan - accuracy: 0.0000e+00\n",
            "Epoch 35: val_loss did not improve from inf\n",
            "1/1 [==============================] - 0s 31ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
            "Epoch 36/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: nan - accuracy: 0.0000e+00\n",
            "Epoch 36: val_loss did not improve from inf\n",
            "1/1 [==============================] - 0s 30ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
            "Epoch 37/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: nan - accuracy: 0.0000e+00\n",
            "Epoch 37: val_loss did not improve from inf\n",
            "1/1 [==============================] - 0s 24ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
            "Epoch 38/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: nan - accuracy: 0.0000e+00\n",
            "Epoch 38: val_loss did not improve from inf\n",
            "1/1 [==============================] - 0s 26ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
            "Epoch 39/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: nan - accuracy: 0.0000e+00\n",
            "Epoch 39: val_loss did not improve from inf\n",
            "1/1 [==============================] - 0s 26ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
            "Epoch 40/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: nan - accuracy: 0.0000e+00\n",
            "Epoch 40: val_loss did not improve from inf\n",
            "1/1 [==============================] - 0s 25ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
            "Epoch 41/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: nan - accuracy: 0.0000e+00\n",
            "Epoch 41: val_loss did not improve from inf\n",
            "1/1 [==============================] - 0s 25ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
            "Epoch 42/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: nan - accuracy: 0.0000e+00\n",
            "Epoch 42: val_loss did not improve from inf\n",
            "1/1 [==============================] - 0s 25ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
            "Epoch 43/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: nan - accuracy: 0.0000e+00\n",
            "Epoch 43: val_loss did not improve from inf\n",
            "1/1 [==============================] - 0s 25ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
            "Epoch 44/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: nan - accuracy: 0.0000e+00\n",
            "Epoch 44: val_loss did not improve from inf\n",
            "1/1 [==============================] - 0s 25ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
            "Epoch 45/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: nan - accuracy: 0.0000e+00\n",
            "Epoch 45: val_loss did not improve from inf\n",
            "1/1 [==============================] - 0s 26ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
            "Epoch 46/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: nan - accuracy: 0.0000e+00\n",
            "Epoch 46: val_loss did not improve from inf\n",
            "1/1 [==============================] - 0s 26ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
            "Epoch 47/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: nan - accuracy: 0.0000e+00\n",
            "Epoch 47: val_loss did not improve from inf\n",
            "1/1 [==============================] - 0s 26ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
            "Epoch 48/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: nan - accuracy: 0.0000e+00\n",
            "Epoch 48: val_loss did not improve from inf\n",
            "1/1 [==============================] - 0s 27ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
            "Epoch 49/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: nan - accuracy: 0.0000e+00\n",
            "Epoch 49: val_loss did not improve from inf\n",
            "1/1 [==============================] - 0s 34ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
            "Epoch 50/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: nan - accuracy: 0.0000e+00\n",
            "Epoch 50: val_loss did not improve from inf\n",
            "1/1 [==============================] - 0s 23ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
            "Epoch 50: early stopping\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x14a97a6d2a0>"
            ]
          },
          "execution_count": 61,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.fit(\n",
        "    X_train,\n",
        "    y_train,\n",
        "    epochs=1000,\n",
        "    batch_size=64,\n",
        "    validation_data=(X_test, y_test),\n",
        "    callbacks=[cp_callback, es_callback]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "id": "RBkmDeUW9hE4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
          ]
        }
      ],
      "source": [
        "# Loading the saved model\n",
        "model = tf.keras.models.load_model(model_save_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pxvb2Y299hE3",
        "outputId": "7015e279-0501-4f24-d1b5-90652d2de17d"
      },
      "outputs": [
        {
          "ename": "RuntimeError",
          "evalue": "You must compile your model before training/testing. Use `model.compile(optimizer, loss)`.",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "Cell \u001b[1;32mIn [63], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39m# Model evaluation\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[39m# TODO Test on loaded model\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m val_loss, val_acc \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mevaluate(X_test, y_test, batch_size\u001b[39m=\u001b[39;49m\u001b[39m64\u001b[39;49m)\n",
            "File \u001b[1;32mc:\\Users\\SexyBeazt\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[39m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[39m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[0;32m     71\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[39mdel\u001b[39;00m filtered_tb\n",
            "File \u001b[1;32mc:\\Users\\SexyBeazt\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\training.py:3618\u001b[0m, in \u001b[0;36mModel._assert_compile_was_called\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   3612\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_assert_compile_was_called\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m   3613\u001b[0m     \u001b[39m# Checks whether `compile` has been called. If it has been called,\u001b[39;00m\n\u001b[0;32m   3614\u001b[0m     \u001b[39m# then the optimizer is set. This is different from whether the\u001b[39;00m\n\u001b[0;32m   3615\u001b[0m     \u001b[39m# model is compiled\u001b[39;00m\n\u001b[0;32m   3616\u001b[0m     \u001b[39m# (i.e. whether the model is built and its inputs/outputs are set).\u001b[39;00m\n\u001b[0;32m   3617\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_is_compiled:\n\u001b[1;32m-> 3618\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\n\u001b[0;32m   3619\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mYou must compile your model before \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   3620\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mtraining/testing. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   3621\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mUse `model.compile(optimizer, loss)`.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   3622\u001b[0m         )\n",
            "\u001b[1;31mRuntimeError\u001b[0m: You must compile your model before training/testing. Use `model.compile(optimizer, loss)`."
          ]
        }
      ],
      "source": [
        "# Model evaluation\n",
        "# TODO Test on loaded model\n",
        "val_loss, val_acc = model.evaluate(X_test, y_test, batch_size=64)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tFz9Tb0I9hE4",
        "outputId": "bb8a62a9-bf7d-4d99-8099-bda4e2e1c73a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[1.0000000e+00 8.5401677e-12 1.5222527e-14 7.2429063e-11 3.3295724e-09\n",
            " 2.5334020e-27 2.3049776e-16 3.3789385e-19]\n",
            "0\n"
          ]
        }
      ],
      "source": [
        "# Inference test\n",
        "predict_result = model.predict(np.array([X_test[0]]))\n",
        "print(np.squeeze(predict_result))\n",
        "print(np.argmax(np.squeeze(predict_result)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S3U4yNWx9hE4"
      },
      "source": [
        "# Confusion matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 646
        },
        "id": "AP1V6SCk9hE5",
        "outputId": "efce96b9-ca1c-44a5-ef77-58f1d5fc154c"
      },
      "outputs": [
        {
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'seaborn'",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "Cell \u001b[1;32mIn [49], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mpandas\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mpd\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mseaborn\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39msns\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mmatplotlib\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpyplot\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mplt\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msklearn\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmetrics\u001b[39;00m \u001b[39mimport\u001b[39;00m confusion_matrix, classification_report\n",
            "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'seaborn'"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "\n",
        "def print_confusion_matrix(y_true, y_pred, report=True):\n",
        "    labels = sorted(list(set(y_true)))\n",
        "    cmx_data = confusion_matrix(y_true, y_pred, labels=labels)\n",
        "    \n",
        "    df_cmx = pd.DataFrame(cmx_data, index=labels, columns=labels)\n",
        " \n",
        "    fig, ax = plt.subplots(figsize=(7, 6))\n",
        "    sns.heatmap(df_cmx, annot=True, fmt='g' ,square=False)\n",
        "    ax.set_ylim(len(set(y_true)), 0)\n",
        "    plt.show()\n",
        "    \n",
        "    if report:\n",
        "        print('Classification Report')\n",
        "        print(classification_report(y_test, y_pred))\n",
        "\n",
        "Y_pred = model.predict(X_test)\n",
        "y_pred = np.argmax(Y_pred, axis=1)\n",
        "\n",
        "print_confusion_matrix(y_test, y_pred)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FNP6aqzc9hE5"
      },
      "source": [
        "# Convert to model for Tensorflow-Lite"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ODjnYyld9hE6"
      },
      "outputs": [],
      "source": [
        "# Save as a model dedicated to inference\n",
        "model.save(model_save_path, include_optimizer=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zRfuK8Y59hE6",
        "outputId": "106250fb-84e1-4ee8-bc8e-dcedb2bfd31c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/tmpb_379rn7/assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/tmpb_379rn7/assets\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "7840"
            ]
          },
          "execution_count": 89,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Transform model (quantization)\n",
        "\n",
        "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
        "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
        "tflite_quantized_model = converter.convert()\n",
        "\n",
        "open(tflite_save_path, 'wb').write(tflite_quantized_model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CHBPBXdx9hE6"
      },
      "source": [
        "## Inference test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mGAzLocO9hE7"
      },
      "outputs": [],
      "source": [
        "interpreter = tf.lite.Interpreter(model_path=tflite_save_path)\n",
        "interpreter.allocate_tensors()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oQuDK8YS9hE7"
      },
      "outputs": [],
      "source": [
        "# Get I / O tensor\n",
        "input_details = interpreter.get_input_details()\n",
        "output_details = interpreter.get_output_details()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2_ixAf_l9hE7"
      },
      "outputs": [],
      "source": [
        "interpreter.set_tensor(input_details[0]['index'], np.array([X_test[0]]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s4FoAnuc9hE7",
        "outputId": "330d050b-a3fb-41ce-fa07-dc7a48d715e7",
        "scrolled": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CPU times: user 117 µs, sys: 7 µs, total: 124 µs\n",
            "Wall time: 132 µs\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "# Inference implementation\n",
        "interpreter.invoke()\n",
        "tflite_results = interpreter.get_tensor(output_details[0]['index'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vONjp19J9hE8",
        "outputId": "9338c9f1-499b-4e10-844d-950075e98a75"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[1.0000000e+00 1.7798680e-13 5.1755124e-26 1.1783223e-18 1.0188586e-18\n",
            " 1.1212574e-26 2.5901723e-24 2.6419864e-15]\n",
            "0\n"
          ]
        }
      ],
      "source": [
        "print(np.squeeze(tflite_results))\n",
        "print(np.argmax(np.squeeze(tflite_results)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2GCHB0ELGs60"
      },
      "source": [
        "## Download model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a2jM8I3jGdF6",
        "outputId": "bd2c08cc-d57c-4589-e4fa-f80389176b96"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "updating: keypoint_classifier/ (stored 0%)\n",
            "updating: keypoint_classifier/keypoint_classifier.tflite (deflated 22%)\n",
            "updating: keypoint_classifier/keypoint_classifier.hdf5 (deflated 60%)\n"
          ]
        }
      ],
      "source": [
        "!zip -r model.zip keypoint_classifier  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vEqyprC6cMVF"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "# ❗️Hyperparameters Tuning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KrjjSqlLcQ4O"
      },
      "outputs": [],
      "source": [
        "%load_ext tensorboard\n",
        "from tensorboard.plugins.hparams import api as hp"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YO6VffaRcY3R"
      },
      "outputs": [],
      "source": [
        "# Init parameters to tune\n",
        "HP_NUM_UNITS_1 = hp.HParam('num_units_1', hp.Discrete([16, 32, 64]))\n",
        "HP_NUM_UNITS_2 = hp.HParam('num_units_2', hp.Discrete([8, 16, 32]))\n",
        "HP_NUM_UNITS_3 = hp.HParam('num_units_3', hp.Discrete([8, 16, 32]))\n",
        "HP_DROPOUT = hp.HParam('dropout', hp.RealInterval(0.0, 0.2))\n",
        "HP_OPTIMIZER = hp.HParam('optimizer', hp.Discrete(['adam', 'sgd']))\n",
        "\n",
        "METRIC_ACCURACY = 'accuracy'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eMysvzFxctmG"
      },
      "outputs": [],
      "source": [
        "with tf.summary.create_file_writer('logs/hparam_tuning').as_default():\n",
        "  hp.hparams_config(\n",
        "    hparams=[HP_NUM_UNITS_1,HP_NUM_UNITS_2,HP_NUM_UNITS_3, HP_DROPOUT, HP_OPTIMIZER],\n",
        "    metrics=[hp.Metric(METRIC_ACCURACY, display_name='Accuracy')],\n",
        "  )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XSDYqpKZgOBw"
      },
      "outputs": [],
      "source": [
        "# Model checkpoint callback\n",
        "cp_callback = tf.keras.callbacks.ModelCheckpoint(\n",
        "    model_save_path, verbose=1, save_weights_only=False, save_best_only=True)\n",
        "# Callback for early stopping\n",
        "es_callback = tf.keras.callbacks.EarlyStopping(patience=15, verbose=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8ssEmXpJcxSp"
      },
      "outputs": [],
      "source": [
        "def train_test_model(hparams):\n",
        "\n",
        "  model = tf.keras.models.Sequential([\n",
        "    tf.keras.layers.Input((21 * 2, )),\n",
        "    tf.keras.layers.Dropout(hparams[HP_DROPOUT]),\n",
        "    tf.keras.layers.Dense(hparams[HP_NUM_UNITS_1], activation='relu'),\n",
        "    tf.keras.layers.Dropout(hparams[HP_DROPOUT]),\n",
        "    tf.keras.layers.Dense(hparams[HP_NUM_UNITS_2], activation='relu'),\n",
        "    tf.keras.layers.Dropout(hparams[HP_DROPOUT]),\n",
        "    tf.keras.layers.Dense(hparams[HP_NUM_UNITS_3], activation='relu'),\n",
        "    tf.keras.layers.Dense(NUM_CLASSES, activation='softmax')\n",
        "])\n",
        "  \n",
        "  model.compile(\n",
        "    optimizer=hparams[HP_OPTIMIZER],\n",
        "    loss='sparse_categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "  \n",
        "  cp_callback = tf.keras.callbacks.ModelCheckpoint(\n",
        "    model_save_path, verbose=1, save_weights_only=False, save_best_only=True)\n",
        "\n",
        "  model.fit(\n",
        "    X_train,\n",
        "    y_train,\n",
        "    epochs=50,\n",
        "    batch_size=64,\n",
        "    validation_data=(X_test, y_test),\n",
        "    callbacks=[\n",
        "               cp_callback,\n",
        "               es_callback,\n",
        "               ]\n",
        "  ) \n",
        "\n",
        "  # Load model with best accuracy\n",
        "  model = tf.keras.models.load_model(model_save_path)\n",
        "\n",
        "  _, accuracy = model.evaluate(X_test, y_test)\n",
        "  return accuracy\n",
        "\n",
        "def run(run_dir, hparams):\n",
        "  with tf.summary.create_file_writer(run_dir).as_default():\n",
        "    hp.hparams(hparams)  # record the values used in this trial\n",
        "    accuracy = train_test_model(hparams)\n",
        "    tf.summary.scalar(METRIC_ACCURACY, accuracy, step=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5pO9W84DdHVL"
      },
      "outputs": [],
      "source": [
        "session_num = 0\n",
        "\n",
        "for num_units_1 in HP_NUM_UNITS_1.domain.values:\n",
        "  for num_units_2 in HP_NUM_UNITS_2.domain.values:\n",
        "    for num_units_3 in HP_NUM_UNITS_3.domain.values:\n",
        "      for dropout_rate in np.arange(HP_DROPOUT.domain.min_value, HP_DROPOUT.domain.max_value, 0.1):\n",
        "        for optimizer in HP_OPTIMIZER.domain.values:\n",
        "          hparams = {\n",
        "              HP_NUM_UNITS_1: num_units_1,\n",
        "              HP_NUM_UNITS_2: num_units_2,\n",
        "              HP_NUM_UNITS_3: num_units_3,\n",
        "              HP_DROPOUT: dropout_rate,\n",
        "              HP_OPTIMIZER: optimizer,\n",
        "          }\n",
        "          run_name = \"run-%d\" % session_num\n",
        "          print('--- Starting trial: %s' % run_name)\n",
        "          print({h.name: hparams[h] for h in hparams})\n",
        "          run('logs/hparam_tuning/' + run_name, hparams)\n",
        "          session_num += 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "21knbMYldaUn"
      },
      "outputs": [],
      "source": [
        "# !ATTENTION! Works only in Colab\n",
        "%tensorboard --logdir logs/hparam_tuning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J6_UH6jttBsD"
      },
      "outputs": [],
      "source": [
        "!rm -rf logs"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "Keypoint_model_training.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3.10.2 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.2"
    },
    "vscode": {
      "interpreter": {
        "hash": "b9ceb6581300fd178650f906bc96bb1776f1f16142961cd86ff07f2e07d02e59"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
